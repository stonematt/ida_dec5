{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### going back to the election results project\n",
    "In A survey of 70 individuals, 47% chose Ceballos.  In the election, Ceballos earned 54% of th vote and won the election.\n",
    "\n",
    "Using a binomial distibution form numpy, we predicted Ceballos would lose in ~64% of the cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survey suggests Ceballos had 64.13% chance of losing\n",
      "or a 35.87% chance of winning\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "possible_surveys = np.random.binomial(70, \\\n",
    "                                      0.471428571429, \\\n",
    "                                      size=10000) / 70\n",
    "# how likely did the survey predict that\n",
    "# Ceballos would loose, (i.e. get < 50%)\n",
    "ceballos_loss_surveys = np.mean(possible_surveys < 0.5)\n",
    "print(\"survey suggests Ceballos had {0:.2f}% chance of losing\".format(ceballos_loss_surveys * 100))\n",
    "print(\"or a {0:.2f}% chance of winning\".format(100-(ceballos_loss_surveys * 100)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post election analysis: Caballos won...\n",
    "Since Caballos won w/ 54% of the vote, we can use that to consider the survey methodology.  Compare reality in the observed reality (54%) to the predicted outcome (47%)...\n",
    "\n",
    "## @Jawells slack comment\n",
    "\n",
    "https://codecademyintensive.slack.com/archives/C88QH8YV6/p1515885315000001\n",
    "> I would say that you should use 0.57 as the probability for checking your survey. Here's why: we wanted to find out something about the population of people who were going to vote in the election (10000) by taking a sample, the 70 people who you surveyed. Your survey said 47% of people would vote for Ceballos, but since the election has happened you know that the true proportion was actually 54%. Since you know the true probability is 0.54, that is what you should compare to. So you should look at possible_surveys = np.random.binomial(70, .54,10000)/70.0 which says if I have a population of 10000 people, 54% of which favor Ceballos AND I sample 70 of those, what proportion of these samples will predict a loss for Ceballos. In my calculation it was about 21%. Then, when you survey 7000 of the 10000 people, your survey will never predict a loss for Ceballos, showing that increasing the sample size improves your prediction. This is how you know p should NOT be 0.47, because in that case it would predict a loss for Ceballos 100% of the time if you upped your sample size to 7000, which you know is wrong.\n",
    "\n",
    "`i think @jawells meant 0.54 above (not 0.57)`\n",
    "\n",
    "https://codecademyintensive.slack.com/archives/C88QH8YV6/p1515885648000047\n",
    "\n",
    "> It's also a good idea to step back and ask yourself what could explain your results. For instance, your survey could be wrong because instead of surveying only people who are eligible to vote in the Shelbyville election between Ceballos and Kerrigan. you accidentally surveyed people from Springfield, who were ineligible to vote here. In which case, you would need to change how you select your survey participants. But this analysis shows that the failure of your survey to predict the actual result could simply be due to chance. So unless you have some independent reason to believe that your sample included ineligible voters, the perhaps the best course of action for next election would be to simply increase your sample size, if you can afford it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowing the acutual results, that Ceballos got 54% of the vote, \n",
      "surveying 70 people of 10,000 would predict Ceballos losing 21.10% of the time\n",
      "or winning 78.90% of the time\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# in reality, we KNOW 57% actually voted for Ceballos in the election.\n",
    "# So, using 0.54, how likely was it that we would get a losing prediction(<50%) \n",
    "# in our suvey of 70 people?\n",
    "possible_surveys54 = np.random.binomial(70, \\\n",
    "                                      0.54, \\\n",
    "                                      size=10000) / 70\n",
    "# how likely would a sample size of 70 predict that\n",
    "# Ceballos would lose, (i.e. get < 50%)\n",
    "ceballos_loss_surveys54 = np.mean(possible_surveys57 < 0.5)\n",
    "print(\"Knowing the acutual results, that Ceballos got 54% of the vote, \")\n",
    "print(\"surveying 70 people of 10,000 would predict Ceballos losing {0:.2f}% of the time\".format(ceballos_loss_surveys54 * 100))\n",
    "print(\"or winning {0:.2f}% of the time\".format(100-(ceballos_loss_surveys54 * 100)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## what about the confidence in the survey?\n",
    "\n",
    "In scipy.stats we can do a binom test to understand if the observed outcome (54% of the vote) is due to random change based on the survey we did. \n",
    "* H(0): the difference between the sample 47% and real outcome of 54% is due to sampling, not survey design\n",
    "* H(a): the difference is real so so the suvey is likely flawed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.40149684593e-44\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import binom_test\n",
    "# we observed 5400 of 10000 voters selected Ceballos, but we expected 47%\n",
    "pval = binom_test(5400, n=10000, p=0.47)\n",
    "print(pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pval is very small ~1.4e-44, so we reject the null hypothesis.  This is not sampling error,  suvey wasn't a good indicator."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
